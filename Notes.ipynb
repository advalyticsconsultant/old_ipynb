{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4ff1fe-c19d-4460-ae73-dd72139b7ff2",
   "metadata": {},
   "source": [
    "# Other questions\n",
    "- ~what is regularization?~\n",
    "- ~how to optimize a linear regression model?~\n",
    "- how to choose a value for the regularization parameter?\n",
    "- what is gridsearch?\n",
    "- what is cross-validation?\n",
    "- how to handle missing values?\n",
    "- how to optimize a logistic regression model?\n",
    "- other metrics to evaluate:\n",
    "    - a linear regression model\n",
    "    - a logistic regression model\n",
    "- Chi-squared test\n",
    "- Wald's test\n",
    "- p-values\n",
    "- F1 score\n",
    "- normal distribution and its impact on machine learning\n",
    "- assess whether data is normally distributed\n",
    "- ANOVA\n",
    "- configure threshold value in logistic regression\n",
    "- alternatives to:\n",
    "    - LinearRegression\n",
    "    - LogisticRegression\n",
    "- causes and prevention of overfitting/underfitting\n",
    "- advantages and disadvantage of:\n",
    "    - Z-score normalization\n",
    "    - MinMax normalization\n",
    "    - Robust scaling\n",
    "    - MaxAbs scaling\n",
    "    - OneHot Encoding\n",
    "    - Label Encoding\n",
    "    - Target Encoding\n",
    "    - Embedding\n",
    "- other methods of regularization\n",
    "- data leakage in machine learning\n",
    "- how to optimize a decision tree model?\n",
    "- how to optimize a random forest model?\n",
    "- how to optimize a k-means model?\n",
    "- other metrics to evaluate:\n",
    "    - a decision tree model\n",
    "    - a random forest model\n",
    "- alternatives to:\n",
    "    - DecisionTreeClassifier\n",
    "    - RandomForestClassifier\n",
    "- k-Means Clustering\n",
    "- PCA\n",
    "- LDA\n",
    "- other metrics to evaluate:\n",
    "    - a k-means model\n",
    "- alternatives to:\n",
    "    - KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8762b9-46c0-4be3-85c3-d5f12ffc391b",
   "metadata": {},
   "source": [
    "# Answered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a7459-3b68-4e08-9e00-61d78bc3a94c",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Regularization is a technique through which we identify whether the model is overfitted. It identifies overfitting by adding a \"`penalty`\" to the final score of the model. This \"penalty\" is simply the sum of weights of the model. `For regularization to work, we need to first scale input features appropriately. It does not work with raw (unscaled) input features.`\n",
    "\n",
    "There are mainly two types of regularization methods:\n",
    "1. `Lasso` (`L1`): this adds the sum of absolute weights to the final score. It is applicable in cases where we have limited data, and a lot of input features. This technique aims to reduce the number of input features. While the model is training, the weights are `shrunk` to zero as much as possible, so that ultimately only a few input features are left out of the ones chosen.\n",
    "\n",
    "Mathematically,<br>\n",
    "$\\text{Lasso Regularization} = Score + \\alpha * \\sum |w_i|$\n",
    "\n",
    "| Advantage | Disadvantage |\n",
    "| --- | --- |\n",
    "| applicable when there are a lot of input features | not suitable when input features are correlated to each other |\n",
    "| helps selecting relavant input features | computationally more expensive |\n",
    "\n",
    "2. `Ridge` (`L2`): this adds the sum of squared weights to the final score. It is applicable in cases where the input features are correlated to each other. It aims to spread the influence of a single featire across multiple features. While the model is training, the weights assigned are small and within a small range of values.\n",
    "\n",
    "Mathematically,<br>\n",
    "$\\text{Ridge Regularization} = Score + \\alpha * \\sum (w_i ^ 2)$\n",
    "\n",
    "| Advantage | Disadvantage |\n",
    "| --- | --- |\n",
    "| applicable when input features are correlated to each other | does not help in reducing the number of input features; not very useful with datasets with a lot of input features |\n",
    "| computationally more efficient than Lasso regularization |  |\n",
    "\n",
    "There are cases when we have limited data, with a high number of input features, where the features may be correlated to each other. In such cases, we use a combination of L1 and L2 regularization, called `Elastic-Net` regularization. This method of regularization allows us to select features, and also spread the influence of a single feature across multiple features.\n",
    "\n",
    "Mathematically,<br>\n",
    "$\\text{Elastic-Net Regularization} = Score + \\alpha_L * \\sum |w_i| + \\alpha_R * \\sum (w_i ^ 2)$\n",
    "\n",
    "In all the above, $\\alpha$ is the regularization parameter, chosen by us.\n",
    "\n",
    "| Advantage | Disadvantage |\n",
    "| --- | --- |\n",
    "| applicable when there are a lot of input features | computationally more expensive |\n",
    "| applicable to data where input features are correlated |  |\n",
    "| helps selecting relevant input features |  |\n",
    "| assigns small but similar weights to all input features so that one feature does not influence the entire model |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff439f-8b8b-4def-95eb-48c07a2386ec",
   "metadata": {},
   "source": [
    "### Optimizing a Linear Regression model\n",
    "\n",
    "- handle missing values\n",
    "- scale values\n",
    "- feature engineering: add/remove features\n",
    "- use regularization\n",
    "    - find optimal value of regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdee31f-1cbb-4142-96f6-5887674890df",
   "metadata": {},
   "source": [
    "### Identifying whether model is overfitting or underfitting\n",
    "- if the score on training dataset is smaller than that on test dataset, model is overfit\n",
    "- if the score on training dataset and the test dataset is large and similar, model is underfit\n",
    "- if the score on training dataset and the test dataset is small and similar, model is balanced and could use some optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d31a8-05dd-4b19-b66e-dfaba5b6a537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
