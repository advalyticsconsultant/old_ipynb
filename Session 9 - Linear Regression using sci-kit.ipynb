{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb3abd-fede-456f-b37d-1a10146d3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09632ba8-dcc6-426d-8e26-39cc1b93a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv(r\"https://raw.githubusercontent.com/puneettrainer/datasets/main/student_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea37d9-610d-4908-833b-912337f62694",
   "metadata": {},
   "source": [
    "### Identifying `input` and `target` field\n",
    "\n",
    "We start of by selecting the `input` and `target` field(s) of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8e8b8-ce85-4df4-9557-7d93e8d09791",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6cb98-ce09-4f76-ac43-6b09bbb7d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc81ec1-f704-4c71-b1c0-de5a57ad7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_field = 'Previous Scores'\n",
    "target_field = 'Performance Index'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c3956-2ec5-4669-852c-cc0ca4111596",
   "metadata": {},
   "source": [
    "# Predict `Performance` based on `Previous Score`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f34b1-cb29-4fc4-9f9f-4362c8e4a561",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n",
    "\n",
    "When developing a machine learning model, we split the provided dataset into two datasets:\n",
    "1. `training_data`: dataset which we use to train the model\n",
    "2. `test_data`: dataset which we use to validate the trained model\n",
    "\n",
    "We can use any method to split the dataset (such as `loc`, `iloc`, etc.). Another method provided in the `sci-kit` module is the `train_test_split` function.\n",
    "\n",
    "The dataset can be split in any ratio, but ideally we select a bigger portion of the data for the `training_data` dataset. Just like how we prepare for tests by going through multiple mock tests, a machine learning model learns best when it has a lot of data to study from.\n",
    "\n",
    "The `test_data` dataset should have a lot of records too, but it would be smaller than the `training_data` dataset. `test_data` is used for evaluating the model after it has been trained.\n",
    "\n",
    "Usually a 70:30 ratio is adequate for `training_data` and `test_data`.\n",
    "\n",
    "#### `train_test_split(dataset, test_size, random_state)`\n",
    "\n",
    "This function splits the `dataset` into two dataframes; first the size of (1 - `test_size`) * n rows, the second the size of `test_size` * n rows. `random_state` is used to make sure that whenever the data is split, the same records are assigned to both the datasets. This is useful when developing the model, as during development we may run the notebook multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe6626-1da7-4331-93b1-4ad18d4a1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = train_test_split(performance[[input_field, target_field]]\n",
    "                                           ,test_size=0.3\n",
    "                                           ,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68055f6a-2511-4abe-8ccd-bced9a276a08",
   "metadata": {},
   "source": [
    "### Model Initialization\n",
    "\n",
    "After the data is split, we instantiate the linear regression model using the `LinearRegression()` class. This algorithm tries to fit a line over the data points such that each point is as close to the data points as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a70a2-84ff-4001-b8e3-5ff6015ac0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a Linear Regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1d055-4935-4401-a4ba-39dc41516959",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "To train the model, we pass the `input` and the `target` into the `fit()` method of the `LinearRegression()` class. The `input` is the input field and `target` is the target field in the `training_data` dataset.\n",
    "\n",
    "#### The `fit` method does not accept `Series` input, so we pass a single column dataframe instead.\n",
    "\n",
    "| Syntax | Data Type |\n",
    "| --- | --- |\n",
    "| `data['Field']` | Series |\n",
    "| `data[['Field']]` | single-column dataframe |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb2e14-fbda-4108-bbac-2d8db0d9e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_data[[input_field]], training_data[[target_field]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf113aa-a9fb-4796-9c66-62eb9ee06445",
   "metadata": {},
   "source": [
    "### Making predictions\n",
    "\n",
    "To make predictions from the model, we use the `predict()` method of the `LinearRegression()`. We pass the input field from the `test_data` dataset into this method.\n",
    "\n",
    "#### The `predict` method does not accept `Series` input, so we pass a single column dataframe instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051d64a-54c3-4dcd-98e8-0c76dba2026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_data[[input_field]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb410c3-6fbd-44c5-90cf-6da9240d2172",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Now we compare the Profit predicted by our model to the actual Profit recorded in the `train_data` dataset.\n",
    "\n",
    "So,\n",
    "- `actual` is the actual value of `Performance Index` in `test_data[target_field]` column\n",
    "- `prediction` is the output of the `model.predict(test_data[[input_field]])`\n",
    "\n",
    "For evaluating the model, we can use any evaluation method we see fit for our application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bdb9d0-aef0-4151-a5e0-759fa89a498c",
   "metadata": {},
   "source": [
    "#### When presence of outliers doesn't matter and we want an easy-to-understand score - MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2276d15-15e5-4ae2-99d8-ae5748a953a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(test_data[target_field], model.predict(test_data[[input_field]]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30762d34-5fe8-42be-9970-27b69616d23f",
   "metadata": {},
   "source": [
    "#### When presence of outliers makes a difference - MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c7eb5-f481-4530-b2fb-10ec04c46b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f'Mean Squared Error: {mean_squared_error(test_data[target_field], model.predict(test_data[[input_field]]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7768797-12bd-48a8-8ea4-ce3c2fb553db",
   "metadata": {},
   "source": [
    "#### When presence of outliers makes a difference and we also want the score to come in the same units as the target field - RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00547208-6029-4ac8-86d2-c27671c8ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "print(f'Root Mean Squared Error: {root_mean_squared_error(test_data[target_field], model.predict(test_data[[input_field]]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c3d2f-3efe-4a19-9bcb-88a85ee7c01f",
   "metadata": {},
   "source": [
    "#### When we want to see what percentage of the predictions made by the model can be explained by the `input_field` - $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f4fcf-975f-4003-9434-c01c3acbe741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(f'R-Squared Score: {r2_score(test_data[target_field], model.predict(test_data[[input_field]]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f85df8-dfb2-4784-ad76-954f91d7075b",
   "metadata": {},
   "source": [
    "From the $R^2$ score, we can see that only $83\\%$ of the predictions of `Performance Index` are explained by `Previous Score`. This means that $83\\%$ of the predictions can be explained by the `Previous Score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee67f6e-6f65-4932-9567-0949ab6fd3b4",
   "metadata": {},
   "source": [
    "### Optimizing/improving a machine learning algorithm\n",
    "\n",
    "There are multiple ways of optimizing a machine learning algortihm, depending on the algorithm that we are using. Some common optimization methods are:\n",
    "- hyperparameter tuning\n",
    "- adding or removing input fields\n",
    "- scaling the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc41e76-28e2-4cce-a2a4-186a0a52dc68",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "\n",
    "In machine learning algorithms, `parameters` are the input variables that we provide to the model to learn patterns in the dataset from. `Hyperparameters` are arguments of a model class that allow us to further configure the model when we instantiate it.\n",
    "\n",
    "For example,<br>\n",
    "```\n",
    "model = LinearRegression()\n",
    "model.fit(training_data[input], training_data[[target]])\n",
    "model.predict(test_data[input])\n",
    "```\n",
    "\n",
    "Here,<br>\n",
    "`training_data[input]`, `training_data[[target]]`, `test_data[input]` are the `parameters` of the `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ade12-b155-408f-86ec-c3279d2159eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LinearRegression(positive=True)\n",
    "model_2.fit(training_data[[input_field]], training_data[[target_field]])\n",
    "\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(test_data[target_field], model_2.predict(test_data[[input_field]]))}')\n",
    "print(f'Mean Squared Error: {mean_squared_error(test_data[target_field], model_2.predict(test_data[[input_field]]))}')\n",
    "print(f'Root Mean Squared Error: {root_mean_squared_error(test_data[target_field], model_2.predict(test_data[[input_field]]))}')\n",
    "print(f'R-Squared Score: {r2_score(test_data[target_field], model_2.predict(test_data[[input_field]]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9b91e-8b7e-46c5-8fdf-15da16c4254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_r2(test_data[target_field], model_2.predict(test_data[[input_field]]), model_2.n_features_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1bdae-41b2-43f3-9bdb-b17be2aff6b0",
   "metadata": {},
   "source": [
    "```\n",
    "model_2 = LinearRegression(positive=True)\n",
    "```\n",
    "\n",
    "Here,<br>\n",
    "`positive` is a hyperparameter of the algorithm. It is used to force the weights of the relationship be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571300d-967b-43ce-9e9a-b07cee5b06fb",
   "metadata": {},
   "source": [
    "### `LinearRegression()` attributes\n",
    "\n",
    "Just like any class, `LinearRegression` has some attributes. These are properties generated by the algorithm when the class is trained.\n",
    "\n",
    "For example, the `pd.DataFrame` class has `attributes` such as `shape`, `columns`, `loc`, etc. Similarly, this class has:\n",
    "- `coef_`: this is the weight computed for the relation (value of `m` in $m * x + c$)\n",
    "- `intercept_`: this is the value of `c`\n",
    "- `n_features_in_`: this is the number of input fields\n",
    "- `features_names_in_`: this is the name of input fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d292835-f788-453c-a94c-946c7cf2c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a5a12-5665-40ea-99a3-5d5ec2e22ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659c8c2-dc45-4e11-8a7d-dd19f8e34e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce1d25-64e4-4f7a-a8a2-2ffcad00d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb14093-e889-42a1-b17f-e872887fdcb4",
   "metadata": {},
   "source": [
    "### Linear Regression using multiple input fields (`Multiple Linear Regression`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4860637-8ba2-447c-9d4c-151920ce13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fields = ['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced']\n",
    "\n",
    "training_data, test_data = train_test_split(performance[input_fields + [target_field]]\n",
    "                                           ,test_size = 0.3\n",
    "                                           ,random_state=0)\n",
    "\n",
    "model_3 = LinearRegression()\n",
    "model_3.fit(training_data[input_fields], training_data[target_field])\n",
    "\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(test_data[target_field], model_3.predict(test_data[input_fields]))}')\n",
    "print(f'Mean Squared Error: {mean_squared_error(test_data[target_field], model_3.predict(test_data[input_fields]))}')\n",
    "print(f'Root Mean Squared Error: {root_mean_squared_error(test_data[target_field], model_3.predict(test_data[input_fields]))}')\n",
    "print(f'R-Squared Score: {r2_score(test_data[target_field], model_3.predict(test_data[input_fields]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40cdc3-5986-4e07-8e08-7273b856c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2(actual, prediction, inputs):\n",
    "    return 1 - ((1 - r2_score(actual, prediction)) * (len(actual) - 1)) / (len(actual) - inputs - 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1ad2b-e191-4e02-a7b0-b5abb027a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_r2(test_data[target_field], model_3.predict(test_data[input_fields]), model_3.n_features_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc74c094-6ddf-484d-afda-77a4f50215be",
   "metadata": {},
   "source": [
    "### Saving model for future use\n",
    "\n",
    "Once we have developed and tested a model, we can save the model for future use by creating a `joblib` file. This file stores the configuration of the model so that we don't have to train it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74d42d-44ce-42fc-979d-1d54e4df73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb\n",
    "\n",
    "# save model\n",
    "linear_regression_model = {'inputs':input_fields\n",
    "                          ,'target':target_field\n",
    "                          ,'model': model_3}\n",
    "jb.dump(linear_regression_model, 'linear_regression.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2bd4e-2d66-497d-8d6e-606b481a13cf",
   "metadata": {},
   "source": [
    "### Importing saved model for usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395a13e-f505-4d72-b625-7e938d437199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "saved_model = jb.load('linear_regression.joblib')\n",
    "\n",
    "# creating an empty dictionary to store input values\n",
    "input_values = {}\n",
    "\n",
    "for feature in ('Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced'):\n",
    "    # fetching input values from user\n",
    "    value = input(f'Enter the {feature.lower()}: ')\n",
    "\n",
    "    # inserting input values into input_values dictionary\n",
    "    input_values.update({feature:float(value)})\n",
    "\n",
    "# displaying predicted value\n",
    "print(f'Predicted performance for provided values is: {saved_model['model'].predict(pd.DataFrame(input_values, index=[0]))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
